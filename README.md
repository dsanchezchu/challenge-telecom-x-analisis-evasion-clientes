# ğŸ“¡ Proyecto ETL TelecomX

## ğŸ¯ DescripciÃ³n del Proyecto

Este proyecto desarrolla un pipeline completo de **ETL (Extract, Transform, Load)** para el anÃ¡lisis de datos de telecomunicaciones de la empresa TelecomX. El objetivo principal es extraer, limpiar, transformar y analizar datos de clientes para obtener insights valiosos sobre el comportamiento del usuario, patrones de churn y mÃ©tricas de negocio.

## ğŸš€ CaracterÃ­sticas Principales

### ğŸ“Œ **ExtracciÃ³n de Datos (Extract)**
- SimulaciÃ³n de API REST de telecomunicaciones
- GeneraciÃ³n de 1,000 registros de clientes con datos realistas
- IntroducciÃ³n controlada de valores nulos para simular datos del mundo real
- Estructura de datos tÃ­pica del sector telecomunicaciones

### ğŸ”§ **TransformaciÃ³n de Datos (Transform)**
- **Limpieza de datos**: Manejo inteligente de valores nulos
- **ValidaciÃ³n de tipos**: CorrecciÃ³n y normalizaciÃ³n de formatos
- **Feature Engineering**: CreaciÃ³n de variables derivadas
- **Control de calidad**: EliminaciÃ³n de outliers y valores inconsistentes

### ğŸ“Š **Carga y AnÃ¡lisis (Load)**
- AnÃ¡lisis exploratorio de datos (EDA)
- Visualizaciones interactivas con matplotlib y seaborn
- CÃ¡lculo de KPIs de negocio
- ExportaciÃ³n de datos procesados
- Dashboard de mÃ©tricas clave

### ğŸ“„ **Reporting**
- Informe ejecutivo automatizado
- AnÃ¡lisis de churn por segmentos
- Recomendaciones estratÃ©gicas basadas en datos
- IdentificaciÃ³n de oportunidades de negocio

## ğŸ› ï¸ TecnologÃ­as Implementadas

```python
# LibrerÃ­as principales
- pandas: ManipulaciÃ³n y anÃ¡lisis de datos
- numpy: Operaciones numÃ©ricas y estadÃ­sticas
- matplotlib: Visualizaciones estÃ¡ticas
- seaborn: Visualizaciones estadÃ­sticas avanzadas
- requests: SimulaciÃ³n de API calls
- json: Manejo de datos JSON
- datetime: Manejo de fechas y tiempo
```

## ğŸ“ Estructura del Proyecto

```
TelecomX-ETL/
â”‚
â”œâ”€â”€ TelecomX_LATAM.ipynb       # Notebook principal con pipeline ETL
â”œâ”€â”€ README.md                  # DocumentaciÃ³n del proyecto
â”œâ”€â”€ telecom_data_processed.csv # Datos procesados (generado)
â””â”€â”€ requirements.txt           # Dependencias del proyecto
```

## ğŸ” Variables del Dataset

| Variable | DescripciÃ³n | Tipo |
|----------|-------------|------|
| `customer_id` | ID Ãºnico del cliente | Integer |
| `plan_type` | Tipo de plan (BÃ¡sico, Premium, Enterprise) | String |
| `monthly_charges` | Cargo mensual en USD | Float |
| `total_charges` | Cargo total histÃ³rico | Float |
| `tenure_months` | Meses de antigÃ¼edad | Integer |
| `data_usage_gb` | Uso de datos en GB | Float |
| `voice_minutes` | Minutos de voz utilizados | Integer |
| `sms_count` | Cantidad de SMS enviados | Integer |
| `region` | RegiÃ³n geogrÃ¡fica | String |
| `churn` | Indicador de abandono (0/1) | Binary |
| `signup_date` | Fecha de registro | Date |

## ğŸ“ˆ Variables Creadas (Feature Engineering)

| Variable | DescripciÃ³n | FÃ³rmula |
|----------|-------------|---------|
| `revenue_per_month` | Ingreso promedio por mes | total_charges / tenure_months |
| `signup_year` | AÃ±o de registro | extract(year from signup_date) |
| `customer_segment` | Segmento por gasto | cut(monthly_charges, bins=3) |

## ğŸš¦ InstalaciÃ³n y Uso

### **Prerrequisitos**
- Python 3.7 o superior
- Jupyter Notebook o Google Colab

### **InstalaciÃ³n**

1. **Clona o descarga el proyecto:**
```bash
# Si tienes git instalado
git clone [URL_DEL_REPOSITORIO]
cd TelecomX-ETL
```

2. **Instala las dependencias:**
```bash
pip install pandas numpy matplotlib seaborn jupyter requests
```

### **EjecuciÃ³n**

1. **Abre el notebook:**
```bash
jupyter notebook TelecomX_LATAM.ipynb
```

2. **Ejecuta las celdas secuencialmente:**
   - Cada secciÃ³n estÃ¡ claramente marcada con emojis
   - Sigue el flujo: ExtracciÃ³n â†’ TransformaciÃ³n â†’ AnÃ¡lisis â†’ Informe

3. **Resultados generados:**
   - Visualizaciones interactivas en el notebook
   - Archivo CSV con datos procesados
   - MÃ©tricas de KPIs impresas en consola
   - Informe ejecutivo completo

## ğŸ“Š Resultados y MÃ©tricas

### **KPIs Principales**
- ğŸ‘¥ **Total de clientes**: 1,000 registros
- ğŸ’° **Ingreso promedio mensual**: ~$45 USD
- âš ï¸ **Tasa de churn**: ~20%
- ğŸ“± **Uso promedio de datos**: ~10 GB
- â±ï¸ **AntigÃ¼edad promedio**: ~36 meses

### **Visualizaciones Incluidas**
1. **DistribuciÃ³n por tipo de plan**: GrÃ¡fico de barras
2. **Tasa de churn por regiÃ³n**: AnÃ¡lisis comparativo
3. **RelaciÃ³n antigÃ¼edad vs cargo**: Scatter plot
4. **DistribuciÃ³n de uso de datos**: Histograma

## ğŸ¯ Insights de Negocio

### **Principales Hallazgos**
- IdentificaciÃ³n de regiones con mayor riesgo de churn
- AnÃ¡lisis de rentabilidad por tipo de plan
- Patrones de uso de datos por segmento
- CorrelaciÃ³n entre antigÃ¼edad y valor del cliente

### **Recomendaciones EstratÃ©gicas**
1. **RetenciÃ³n**: Programas especÃ­ficos para regiones de alto churn
2. **Upselling**: Estrategias basadas en uso de datos
3. **SegmentaciÃ³n**: Ofertas diferenciadas por tipo de plan
4. **FidelizaciÃ³n**: Incentivos para clientes de larga duraciÃ³n

## ğŸ”® PrÃ³ximos Pasos

- [ ] **Machine Learning**: Modelos predictivos de churn
- [ ] **AutomatizaciÃ³n**: Pipeline ETL en producciÃ³n
- [ ] **Dashboard**: Visualizaciones en tiempo real
- [ ] **IntegraciÃ³n**: ConexiÃ³n con APIs reales
- [ ] **Escalabilidad**: Procesamiento de big data

## ğŸ“ Notas TÃ©cnicas

### **Manejo de Datos Faltantes**
- `total_charges`: ImputaciÃ³n por mediana segÃºn plan_type
- `data_usage_gb`: ImputaciÃ³n por media general
- Estrategia conservadora para mantener distribuciones originales

### **Control de Calidad**
- EliminaciÃ³n de valores negativos
- ValidaciÃ³n de rangos lÃ³gicos
- VerificaciÃ³n de consistencia entre variables

### **Reproducibilidad**
- Seed fijo (42) para generaciÃ³n de datos
- CÃ³digo documentado y modular
- Resultados consistentes en mÃºltiples ejecuciones


## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

---

â­ **Â¡Si este proyecto te fue Ãºtil, no olvides darle una estrella!** â­

