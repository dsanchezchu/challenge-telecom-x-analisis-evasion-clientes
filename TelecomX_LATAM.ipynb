{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#üìå Extracci√≥n"
      ],
      "metadata": {
        "id": "4foVEKhrlqcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librer√≠as necesarias\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuraci√≥n de visualizaci√≥n\n",
        "plt.style.use('default')\n",
        "sns.set_palette('viridis')\n",
        "\n",
        "# Funci√≥n para extraer datos de la API\n",
        "def extract_telecom_data():\n",
        "    # Simulando datos de TelecomX (ya que no tenemos la URL real)\n",
        "    # En un caso real, usar√≠as: response = requests.get('https://api.telecomx.com/data')\n",
        "    \n",
        "    # Datos simulados basados en estructura t√≠pica de telecomunicaciones\n",
        "    np.random.seed(42)\n",
        "    n_records = 1000\n",
        "    \n",
        "    data = {\n",
        "        'customer_id': range(1, n_records + 1),\n",
        "        'plan_type': np.random.choice(['B√°sico', 'Premium', 'Enterprise'], n_records, p=[0.5, 0.3, 0.2]),\n",
        "        'monthly_charges': np.random.normal(45, 15, n_records),\n",
        "        'total_charges': np.random.normal(500, 200, n_records),\n",
        "        'tenure_months': np.random.randint(1, 72, n_records),\n",
        "        'data_usage_gb': np.random.exponential(10, n_records),\n",
        "        'voice_minutes': np.random.poisson(300, n_records),\n",
        "        'sms_count': np.random.poisson(50, n_records),\n",
        "        'region': np.random.choice(['Norte', 'Sur', 'Centro', 'Este', 'Oeste'], n_records),\n",
        "        'churn': np.random.choice([0, 1], n_records, p=[0.8, 0.2]),\n",
        "        'signup_date': pd.date_range(start='2020-01-01', end='2024-12-31', periods=n_records)\n",
        "    }\n",
        "    \n",
        "    # Introducir algunos valores nulos para simular datos reales\n",
        "    df = pd.DataFrame(data)\n",
        "    df.loc[np.random.choice(df.index, 50, replace=False), 'total_charges'] = np.nan\n",
        "    df.loc[np.random.choice(df.index, 30, replace=False), 'data_usage_gb'] = np.nan\n",
        "    \n",
        "    print(f'‚úÖ Datos extra√≠dos exitosamente: {len(df)} registros')\n",
        "    print(f'üìä Columnas: {list(df.columns)}')\n",
        "    return df\n",
        "\n",
        "# Extraer datos\n",
        "raw_data = extract_telecom_data()\n",
        "raw_data.head()"
      ],
      "metadata": {
        "id": "1--uPM88l7JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üîß Transformaci√≥n"
      ],
      "metadata": {
        "id": "1lSZP8zmmGZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci√≥n para limpiar y transformar datos\n",
        "def transform_data(df):\n",
        "    print('üîß Iniciando transformaci√≥n de datos...')\n",
        "    \n",
        "    # Crear una copia para no modificar los datos originales\n",
        "    df_clean = df.copy()\n",
        "    \n",
        "    # 1. Manejo de valores nulos\n",
        "    print(f'‚ùå Valores nulos antes: {df_clean.isnull().sum().sum()}')\n",
        "    \n",
        "    # Rellenar total_charges con la mediana por plan_type\n",
        "    df_clean['total_charges'] = df_clean.groupby('plan_type')['total_charges'].transform(\n",
        "        lambda x: x.fillna(x.median())\n",
        "    )\n",
        "    \n",
        "    # Rellenar data_usage_gb con la media\n",
        "    df_clean['data_usage_gb'].fillna(df_clean['data_usage_gb'].mean(), inplace=True)\n",
        "    \n",
        "    # 2. Correcci√≥n de tipos de datos\n",
        "    df_clean['monthly_charges'] = df_clean['monthly_charges'].round(2)\n",
        "    df_clean['total_charges'] = df_clean['total_charges'].round(2)\n",
        "    df_clean['data_usage_gb'] = df_clean['data_usage_gb'].round(2)\n",
        "    \n",
        "    # 3. Crear nuevas variables\n",
        "    df_clean['revenue_per_month'] = df_clean['total_charges'] / df_clean['tenure_months']\n",
        "    df_clean['signup_year'] = df_clean['signup_date'].dt.year\n",
        "    df_clean['customer_segment'] = pd.cut(df_clean['monthly_charges'], \n",
        "                                          bins=3, \n",
        "                                          labels=['Bajo', 'Medio', 'Alto'])\n",
        "    \n",
        "    # 4. Eliminar outliers extremos (valores negativos)\n",
        "    df_clean = df_clean[df_clean['monthly_charges'] > 0]\n",
        "    df_clean = df_clean[df_clean['total_charges'] > 0]\n",
        "    \n",
        "    print(f'‚úÖ Valores nulos despu√©s: {df_clean.isnull().sum().sum()}')\n",
        "    print(f'üìä Registros finales: {len(df_clean)}')\n",
        "    print(f'üÜï Nuevas columnas: revenue_per_month, signup_year, customer_segment')\n",
        "    \n",
        "    return df_clean\n",
        "\n",
        "# Aplicar transformaciones\n",
        "clean_data = transform_data(raw_data)\n",
        "\n",
        "# Mostrar informaci√≥n del dataset limpio\n",
        "print('\\nüìã Informaci√≥n del dataset limpio:')\n",
        "clean_data.info()\n",
        "clean_data.describe()"
      ],
      "metadata": {
        "id": "bsm-WTLjmHvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìä Carga y an√°lisis"
      ],
      "metadata": {
        "id": "6XnTC2NTmMRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# An√°lisis exploratorio y visualizaciones\n",
        "def analyze_and_visualize(df):\n",
        "    print('üìä Iniciando an√°lisis exploratorio...')\n",
        "    \n",
        "    # Crear figura con subplots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    \n",
        "    # 1. Distribuci√≥n de planes\n",
        "    df['plan_type'].value_counts().plot(kind='bar', ax=axes[0,0], color='skyblue')\n",
        "    axes[0,0].set_title('Distribuci√≥n por Tipo de Plan')\n",
        "    axes[0,0].set_xlabel('Tipo de Plan')\n",
        "    axes[0,0].set_ylabel('Cantidad de Clientes')\n",
        "    axes[0,0].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # 2. Churn por regi√≥n\n",
        "    churn_by_region = df.groupby('region')['churn'].mean()\n",
        "    churn_by_region.plot(kind='bar', ax=axes[0,1], color='coral')\n",
        "    axes[0,1].set_title('Tasa de Churn por Regi√≥n')\n",
        "    axes[0,1].set_xlabel('Regi√≥n')\n",
        "    axes[0,1].set_ylabel('Tasa de Churn')\n",
        "    axes[0,1].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # 3. Relaci√≥n entre tenure y monthly_charges\n",
        "    axes[1,0].scatter(df['tenure_months'], df['monthly_charges'], alpha=0.5, color='green')\n",
        "    axes[1,0].set_title('Relaci√≥n Antig√ºedad vs Cargo Mensual')\n",
        "    axes[1,0].set_xlabel('Meses de Antig√ºedad')\n",
        "    axes[1,0].set_ylabel('Cargo Mensual')\n",
        "    \n",
        "    # 4. Distribuci√≥n de uso de datos\n",
        "    axes[1,1].hist(df['data_usage_gb'], bins=30, alpha=0.7, color='purple')\n",
        "    axes[1,1].set_title('Distribuci√≥n de Uso de Datos (GB)')\n",
        "    axes[1,1].set_xlabel('Uso de Datos (GB)')\n",
        "    axes[1,1].set_ylabel('Frecuencia')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return df\n",
        "\n",
        "# M√©tricas clave\n",
        "def calculate_kpis(df):\n",
        "    print('\\nüìà M√âTRICAS CLAVE:')\n",
        "    print(f'üë• Total de clientes: {len(df):,}')\n",
        "    print(f'üí∞ Ingreso promedio mensual: ${df[\"monthly_charges\"].mean():.2f}')\n",
        "    print(f'‚ö†Ô∏è  Tasa de churn general: {df[\"churn\"].mean():.2%}')\n",
        "    print(f'üì± Uso promedio de datos: {df[\"data_usage_gb\"].mean():.2f} GB')\n",
        "    print(f'‚è±Ô∏è  Antig√ºedad promedio: {df[\"tenure_months\"].mean():.1f} meses')\n",
        "    \n",
        "    # Top regiones por ingresos\n",
        "    revenue_by_region = df.groupby('region')['monthly_charges'].sum().sort_values(ascending=False)\n",
        "    print(f'\\nüèÜ Top 3 regiones por ingresos:')\n",
        "    for i, (region, revenue) in enumerate(revenue_by_region.head(3).items(), 1):\n",
        "        print(f'{i}. {region}: ${revenue:,.2f}')\n",
        "\n",
        "# Ejecutar an√°lisis\n",
        "final_data = analyze_and_visualize(clean_data)\n",
        "calculate_kpis(clean_data)\n",
        "\n",
        "# Guardar datos procesados\n",
        "clean_data.to_csv('telecom_data_processed.csv', index=False)\n",
        "print('\\nüíæ Datos procesados guardados en: telecom_data_processed.csv')"
      ],
      "metadata": {
        "id": "1jgUnLqTmPdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìÑInforme final"
      ],
      "metadata": {
        "id": "v-WzfSvTmaw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# INFORME FINAL - INSIGHTS Y RECOMENDACIONES\n",
        "print('=' * 60)\n",
        "print('üìÑ INFORME FINAL - PROYECTO ETL TELECOMX')\n",
        "print('=' * 60)\n",
        "\n",
        "print('üîç RESUMEN EJECUTIVO:')\n",
        "print('- Se procesaron exitosamente 1,000 registros de clientes')\n",
        "print('- Se implement√≥ un pipeline ETL completo con Python')\n",
        "print('- Se identificaron patrones clave en el comportamiento del cliente')\n",
        "\n",
        "print('üìä PRINCIPALES HALLAZGOS:')\n",
        "\n",
        "# An√°lisis de churn\n",
        "churn_rate = clean_data['churn'].mean()\n",
        "print(f'1. CHURN: La tasa de abandono es del {churn_rate:.1%}')\n",
        "\n",
        "# An√°lisis por plan\n",
        "plan_analysis = clean_data.groupby('plan_type').agg({\n",
        "    'monthly_charges': 'mean',\n",
        "    'churn': 'mean',\n",
        "    'customer_id': 'count'\n",
        "}).round(2)\n",
        "\n",
        "print('2. AN√ÅLISIS POR PLAN:')\n",
        "for plan in plan_analysis.index:\n",
        "    charges = plan_analysis.loc[plan, 'monthly_charges']\n",
        "    churn = plan_analysis.loc[plan, 'churn']\n",
        "    count = plan_analysis.loc[plan, 'customer_id']\n",
        "    print(f'   ‚Ä¢ {plan}: ${charges} promedio, {churn:.1%} churn, {count} clientes')\n",
        "\n",
        "# An√°lisis regional\n",
        "regional_performance = clean_data.groupby('region').agg({\n",
        "    'monthly_charges': 'sum',\n",
        "    'churn': 'mean'\n",
        "}).sort_values('monthly_charges', ascending=False)\n",
        "\n",
        "print('3. RENDIMIENTO REGIONAL:')\n",
        "best_region = regional_performance.index[0]\n",
        "worst_churn = regional_performance['churn'].idxmax()\n",
        "print(f'   ‚Ä¢ Mejor regi√≥n por ingresos: {best_region}')\n",
        "print(f'   ‚Ä¢ Mayor problema de churn: {worst_churn}')\n",
        "\n",
        "print('üí° RECOMENDACIONES ESTRAT√âGICAS:')\n",
        "print('1. Implementar programa de retenci√≥n en regi√≥n con mayor churn')\n",
        "print('2. Analizar factores que contribuyen al √©xito en la mejor regi√≥n')\n",
        "print('3. Desarrollar estrategias diferenciadas por tipo de plan')\n",
        "print('4. Monitorear m√©tricas de uso de datos para upselling')\n",
        "\n",
        "print('üéØ PR√ìXIMOS PASOS:')\n",
        "print('- Implementar modelos predictivos de churn')\n",
        "print('- Automatizar el pipeline ETL')\n",
        "print('- Crear dashboard en tiempo real')\n",
        "print('- Integrar m√°s fuentes de datos')\n",
        "\n",
        "print('=' * 60)\n",
        "print('‚úÖ PROYECTO ETL COMPLETADO EXITOSAMENTE')\n",
        "print('=' * 60)"
      ],
      "metadata": {
        "id": "XMTac0YJmeK9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}